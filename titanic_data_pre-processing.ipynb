{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "- PassengerId 整型变量，标识乘客的ID，递增变量，对预测无帮助\n",
    "- Survived 整型变量，标识该乘客是否幸存。0表示遇难，1表示幸存。将其转换为factor变量比较方便处理\n",
    "- Pclass 整型变量，标识乘客的社会-经济状态，1代表Upper，2代表Middle，3代表Lower\n",
    "- Name 字符型变量，除包含姓和名以外，还包含Mr.\n",
    "- Mrs. Dr.这样的具有西方文化特点的信息\n",
    "- Sex 字符型变量，标识乘客性别，适合转换为factor类型变量\n",
    "- Age 整型变量，标识乘客年龄，有缺失值\n",
    "- SibSp 整型变量，代表兄弟姐妹及配偶的个数。其中Sib代表Sibling也即兄弟姐妹，Sp代表Spouse也即配偶\n",
    "- Parch 整型变量，代表父母或子女的个数。其中Par代表Parent也即父母，Ch代表Child也即子女\n",
    "- Ticket 字符型变量，代表乘客的船票号 Fare 数值型，代表乘客的船票价\n",
    "- Cabin 字符型，代表乘客所在的舱位，有缺失值\n",
    "- Embarked 字符型，代表乘客登船口岸，适合转换为factor型变量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter,defaultdict\n",
    "import pandas #ipython notebook\n",
    "import pandas as pd\n",
    "\n",
    "train = pandas.read_csv(\"train.csv\")\n",
    "train.head(5)\n",
    "test=pandas.read_csv(\"test.csv\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#处理 Embarked 特征\n",
    "Embarked_list= train['Embarked'].unique()\n",
    "train['Embarked'].fillna('S',inplace=True)\n",
    "test['Embarked'].fillna('S',inplace=True)\n",
    "train['Embarked']=train['Embarked'].astype('category')\n",
    "test['Embarked']=test['Embarked'].astype('category')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517\tMr.\n",
      "182\tMiss.\n",
      "125\tMrs.\n",
      "64\tWilliam\n",
      "44\tJohn\n",
      "40\tMaster.\n",
      "35\tHenry\n",
      "24\tCharles\n",
      "24\tGeorge\n",
      "24\tJames\n",
      "22\tThomas\n",
      "20\tMary\n",
      "18\tEdward\n",
      "17\tAnna\n",
      "16\tJoseph\n",
      "15\tElizabeth\n",
      "15\tFrederick\n",
      "15\tJohan\n",
      "14\tRichard\n",
      "13\tArthur\n",
      "13\tSamuel\n",
      "12\tAlfred\n",
      "12\tMargaret\n",
      "11\tAlexander\n",
      "11\tMaria\n",
      "11\tPeter\n",
      "10\tJr\n",
      "10\tRobert\n",
      "9\tAndersson\n",
      "9\tErnest\n",
      "9\tKarl\n",
      "9\tLeonard\n",
      "9\tO\n",
      "8\tAlbert\n",
      "8\tAlice\n",
      "8\tAnnie\n",
      "8\tH\n",
      "8\tJ\n",
      "8\tMartin\n",
      "8\tVictor\n",
      "7\tCatherine\n",
      "7\tDavid\n",
      "7\tDr.\n",
      "7\tFrank\n",
      "7\tHelen\n",
      "7\tKate\n",
      "7\tSage\n",
      "7\tde\n",
      "6\tCarter\n",
      "6\tE\n"
     ]
    }
   ],
   "source": [
    "# 分割姓名称谓并统计数据\n",
    "import re #正则表达式\n",
    "name_pattern=re.compile('[A-Za-z]+\\.?')\n",
    "name_list= train['Name'].to_numpy()\n",
    "words=Counter(word for name in name_list for word in re.findall(name_pattern,name))\n",
    "words=list((-c,key) for key,c in words.items())\n",
    "words.sort()\n",
    "#展示name中单词的统计频次\n",
    "for c,word in words[:50]:\n",
    "    print(\"{:d}\\t{}\".format(-c,word))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#可以提取称谓作为新特征\n",
    "title_list=tuple(w for c,w in filter(lambda cw:'.'==cw[1][-1] and -cw[0]>6,words))\n",
    "def get_title(name_list):\n",
    "    titleMatrix=[None]*len(title_list)\n",
    "    for i,key in enumerate(title_list):\n",
    "        titleMatrix[i]=list(int(key in name) for name in name_list)\n",
    "    titleMatrix=pd.concat(tuple(map(pd.Series,titleMatrix)),axis=1)\n",
    "    titleMatrix.columns=title_list\n",
    "    return titleMatrix\n",
    "train_titles=get_title(name_list)\n",
    "test_titles=get_title(test['Name'].to_numpy(dtype='float32'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 去掉无效特征并添加新特征\n",
    "drop_cols=['Name','Ticket','Cabin','PassengerId']\n",
    "train.drop(drop_cols,axis=1)\n",
    "train=pd.concat([train,train_titles],axis=1)\n",
    "test.drop(drop_cols,axis=1)\n",
    "test=pd.concat([train,test_titles],axis=1)\n",
    "#数据浮点数化\n",
    "isMail=train[\"Sex\"]=='male'\n",
    "train[\"Sex\"].loc[isMail]=0.0\n",
    "train[\"Sex\"].loc[~isMail]=1.0\n",
    "to_float_cols=[\"Pclass\",\"Survived\",\"SibSp\",\"Parch\"]\n",
    "for col in to_float_cols:\n",
    "    train[col].astype('float32')\n",
    "    test[col].astype('float32')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Mr.', 'Miss.', 'Mrs.', 'Master.', 'Dr.', 'Mr.', 'Miss.', 'Mrs.', 'Master.', 'Dr.']\n",
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Mr.', 'Miss.', 'Mrs.', 'Master.', 'Dr.', 'Mr.', 'Miss.', 'Mrs.', 'Master.', 'Dr.']\n"
     ]
    }
   ],
   "source": [
    "# train.describe()\n",
    "# 训练年龄预测模型\n",
    "naAge_train=train['Age'].isna()\n",
    "naAge_test=test['Age'].isna()\n",
    "# 注意预测age不能使用Survived属性\n",
    "def getXYofAge(data:pd.DataFrame):\n",
    "    column=list(data.columns)\n",
    "    print(column)\n",
    "    column.remove('Age')\n",
    "    return data[column],data['Age']\n",
    "    # return np.ndarray(data[column],dtype='float64'),np.ndarray(data['Age'],dtype='float64')\n",
    "AgeTrainX,AgeTrainY=getXYofAge(train[test.columns].loc[~naAge_train])\n",
    "AgeTestX,AgeTestY=getXYofAge(test.loc[~naAge_test])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\java_lee\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or categorical.  When\n                categorical type is supplied, DMatrix parameter\n                `enable_categorical` must be set to `True`.Name, Sex, Ticket, Cabin, Embarked",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-0da4178ed6dc>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;31m# python 语法，字典对象前加两个*可以转化成以key为参数名且对应value为参数值带入到方法参数列表中。\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mxgboost\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mxgb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mxgb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mXGBClassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mAgeTrainX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mAgeTrainY\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mAgeTestX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    420\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    421\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 422\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    423\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    424\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[0;32m    901\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_features_in_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_features_count\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    902\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 903\u001B[1;33m         train_dmatrix, evals = self._wrap_evaluation_matrices(\n\u001B[0m\u001B[0;32m    904\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgroup\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbase_margin\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbase_margin\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    905\u001B[0m             \u001B[0mfeature_weights\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfeature_weights\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001B[0m in \u001B[0;36m_wrap_evaluation_matrices\u001B[1;34m(self, X, y, group, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, eval_group, label_transform)\u001B[0m\n\u001B[0;32m    263\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    264\u001B[0m         \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlabel_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 265\u001B[1;33m         train_dmatrix = DMatrix(data=X, label=y, weight=sample_weight,\n\u001B[0m\u001B[0;32m    266\u001B[0m                                 \u001B[0mbase_margin\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbase_margin\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    267\u001B[0m                                 missing=self.missing, nthread=self.n_jobs)\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, enable_categorical)\u001B[0m\n\u001B[0;32m    498\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    499\u001B[0m         \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdispatch_data_backend\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 500\u001B[1;33m         handle, feature_names, feature_types = dispatch_data_backend(\n\u001B[0m\u001B[0;32m    501\u001B[0m             \u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmissing\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmissing\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    502\u001B[0m             \u001B[0mthreads\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnthread\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\data.py\u001B[0m in \u001B[0;36mdispatch_data_backend\u001B[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001B[0m\n\u001B[0;32m    537\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0m_from_tuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmissing\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeature_names\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeature_types\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    538\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0m_is_pandas_df\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 539\u001B[1;33m         return _from_pandas_df(data, enable_categorical, missing, threads,\n\u001B[0m\u001B[0;32m    540\u001B[0m                                feature_names, feature_types)\n\u001B[0;32m    541\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0m_is_pandas_series\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\data.py\u001B[0m in \u001B[0;36m_from_pandas_df\u001B[1;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001B[0m\n\u001B[0;32m    240\u001B[0m def _from_pandas_df(data, enable_categorical, missing, nthread,\n\u001B[0;32m    241\u001B[0m                     feature_names, feature_types):\n\u001B[1;32m--> 242\u001B[1;33m     data, feature_names, feature_types = _transform_pandas_df(\n\u001B[0m\u001B[0;32m    243\u001B[0m         data, enable_categorical, feature_names, feature_types)\n\u001B[0;32m    244\u001B[0m     return _from_numpy_array(data, missing, nthread, feature_names,\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\data.py\u001B[0m in \u001B[0;36m_transform_pandas_df\u001B[1;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001B[0m\n\u001B[0;32m    205\u001B[0m                 \u001B[0mcategorical\u001B[0m \u001B[0mtype\u001B[0m \u001B[1;32mis\u001B[0m \u001B[0msupplied\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mDMatrix\u001B[0m \u001B[0mparameter\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    206\u001B[0m                 `enable_categorical` must be set to `True`.\"\"\"\n\u001B[1;32m--> 207\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmsg\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m', '\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbad_fields\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    208\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mfeature_names\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mmeta\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: DataFrame.dtypes for data must be int, float, bool or categorical.  When\n                categorical type is supplied, DMatrix parameter\n                `enable_categorical` must be set to `True`.Name, Sex, Ticket, Cabin, Embarked"
     ]
    }
   ],
   "source": [
    "# 对年龄缺失值进行预测(包括原训练组和测试组)\n",
    "params={\n",
    "    'n_estimators':200,\n",
    "    'objective':'binary:logistic',\n",
    "    'max_depth':4,\n",
    "    'learning_rate':0.1\n",
    "}\n",
    "# python 语法，字典对象前加两个*可以转化成以key为参数名且对应value为参数值带入到方法参数列表中。\n",
    "import xgboost as xgb\n",
    "model=xgb.XGBClassifier(**params).fit(AgeTrainX,AgeTrainY)\n",
    "y_test=model.predict(AgeTestX)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = [round(value) for value in y_test]\n",
    "# evaluate predictions\n",
    "accuracy =  accuracy_score(AgeTestY, predictions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}